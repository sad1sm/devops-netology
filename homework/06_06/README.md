## Задача 1


- напишите список операций, которые вы будете производить для остановки запроса пользователя
  
Найдем операцию висящую больше чем 3 минуты (180 сек):  
`db.currentOp( { "secs_running" : { $gt : 180 } } )`  
Остановим операцию по opid:  
`db.killOp(opid)`  

- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

Сперва проанализируем запросы с помощью explain(), потом, в зависимости от результата, можем перестроить индекс, пересмотреть политику настройки работы с репликами, настроить шардирование, ну или если все не помогает- увеличить производительность серверов.


## Задача 2

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

- Первая возможная причина: во время масштабирования сервиса идет запись большого количества данных. Рост отношения записанных значений к истекшим наводит нас на то, что эти операции производятся в первую очередь, а блокирование операций записи во вторую очередь говорит о том, что производится очистка значений с истекшим сроком, так как Redis выполняет операции последовательно. Причина скорее всего временная и пропадет когда все операции будут выполнены.  
- Вторая, менее вероятная: активный метод удаления ключей с истекшим TTL, в этом случае ключи удаляются раз в 100 мс (10 раз в секунду). Если более 25% ключей истекли то процедура повторяется циклически до достижения значения меньше 25% истекших ключей, тем самым производит блокировку записи.
- Так же может быть недостаточно ОЗУ и проблема может быть в настройке ядра ОС Transparent Huge Pages.

## Задача 3
  
Как вы думаете, почему это начало происходить и как локализовать проблему?
  
Какие пути решения данной проблемы вы можете предложить?
  
Проблемы такого характера могут возникать из-за сетевых проблем.  
Из-за больших запросов, тогда можно попробовать увеличить параметр net_read_timeout (по умолчанию 30 сек).  
Возможно проблема в параметре connect_timeout, ее можно выявить выяснив значение `SHOW GLOBAL STATUS LIKE 'Aborted_connects'`.  
Возможно проблема в BLOB значениях, которые больше параметра max_allowed_packet, такую проблему подтверждает ошибка ER_NET_PACKET_TOO_LARGE.  
  
## Задача 4

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

Причина в нехватке ОЗУ.
Решить проблему можно увеличив кол-во оперативной памяти на сервере или настройкой нескольких параметров в конфигурации используя формулу (shared_buffers + (temp_buffers + work_mem) * max_connections).
